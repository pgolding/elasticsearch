{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import index\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q, Index\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")\n",
    "\n",
    "#r = index.load_sid_examples(settings={ \"settings\": { \"number_of_shards\": 1 }},set=3)\n",
    "#print('{} items created'.format(len(r['items'])))\n",
    "\n",
    "# Let's repopulate the index as we deleted 'gb' in earlier chapters:\n",
    "# Run the script: populate.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Postcodes and Structured Data\n",
    "\n",
    "Assuming we are indexing UK postcodes (like `\"W1V 3DG\"`).\n",
    "\n",
    "* W1V: This outer part identifies the postal area and district:\n",
    "\n",
    "    * W indicates the area (one or two letters)\n",
    "    * 1V indicates the district (one or two numbers, possibly followed by a letter)\n",
    "\n",
    "* 3DG: This inner part identifies a street or building:\n",
    "    * 3 indicates the sector (one number)\n",
    "    * DG indicates the unit (two letters)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's confirm how the most_fields query works by validating the query\n",
    "body= {\n",
    "    \"settings\": { \"number_of_shards\": 1 },\n",
    "    \"mappings\": {\n",
    "        \"address\": {\n",
    "            \"properties\": {\n",
    "                \"postcode\": {\n",
    "                    \"type\":  \"string\",\n",
    "                    \"index\": \"not_analyzed\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index.create_my_index(body=body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now index some postcodes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'postcode': 'W1V 3DG'}\n",
      "{'postcode': 'W2F 8HW'}\n",
      "{'postcode': 'W1F 7HW'}\n",
      "{'postcode': 'WC1N 1LZ'}\n",
      "{'postcode': 'SW5 0BE'}\n"
     ]
    }
   ],
   "source": [
    "# Adding the **and** operator\n",
    "zips = [ \"W1V 3DG\", \"W2F 8HW\", \"W1F 7HW\", \"WC1N 1LZ\", \"SW5 0BE\" ]\n",
    "for i,postcode in enumerate(zips):\n",
    "    body = {}\n",
    "    body['postcode'] = zips[i]\n",
    "    print(body)\n",
    "    r = es.create(index='my_index', doc_type='address', id=i, body=body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prefix Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/address/0): {'postcode': 'W1V 3DG'}>, <Hit(my_index/address/2): {'postcode': 'W1F 7HW'}>]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('prefix', postcode=\"W1\"))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: he prefix query or filter are useful for ad hoc prefix matching, but should be used with care. They can be used freely on fields with a small number of terms, but they scale poorly and can put your cluster under a lot of strain.\n",
    "\n",
    "#### Wildcard and regexp Queries\n",
    "\n",
    "The wildcard query is a low-level, term-based query similar in nature to the prefix query, but it allows you to specify a pattern instead of just a prefix. It uses the standard shell wildcards: ? matches any character, and * matches zero or more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/address/1): {'postcode': 'W2F 8HW'}>, <Hit(my_index/address/2): {'postcode': 'W1F 7HW'}>]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wildcards\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('wildcard', postcode=\"W?F*HW\"))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/address/0): {'postcode': 'W1V 3DG'}>, <Hit(my_index/address/1): {'postcode': 'W2F 8HW'}>, <Hit(my_index/address/2): {'postcode': 'W1F 7HW'}>]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('regexp', postcode=\"W[0-9].+\"))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query-Time Search-as-you-Type\n",
    "\n",
    "In [Phrase Matching](Proximity%20Matching.ipynb#Phrase-Matching) the `match_phrase` matches all the specified words in the same positions relative to each other. For-query time search-as-you-type, we can use a specialization of this query, called the match_phrase_prefix query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'title': 'The quick brown fox'}>, <Hit(my_index/my_type/2): {'title': 'The quick brown fox jumps over the lazy dog'}>, <Hit(my_index/my_type/3): {'title': 'The quick brown fox jumps over the quick dog'}>]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('match_phrase_prefix', title=\"quick brown f\"))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would look for:\n",
    "\n",
    "* quick\n",
    "* Followed by brown\n",
    "* Followed by words beginning with f\n",
    "\n",
    "Like the `match_phrase` query, it accepts a `slop` parameter (see [Mixing It Up](Proximity%20Matching.ipynb#Mixing-It-Up)) to make the word order and relative positions somewhat less rigid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'title': 'The quick brown fox'}>, <Hit(my_index/my_type/2): {'title': 'The quick brown fox jumps over the lazy dog'}>, <Hit(my_index/my_type/3): {'title': 'The quick brown fox jumps over the quick dog'}>]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding some slop\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('match_phrase_prefix', title={\"query\": \"brown quick f\", \"slop\":2}))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "Even though the words are in the wrong order, the query still matches because we have set a high enough slop value to allow some flexibility in word positions. However, it is always only the last word in the query string that is treated as a prefix.\n",
    "\n",
    "Earlier, in [prefix Query](#Prefix-Query), we warned about the perils of the prefix—how prefix queries can be resource intensive. The same is true in this case. A prefix of a could match hundreds of thousands of terms. Not only would matching on this many terms be resource intensive, but it would also not be useful to the user.\n",
    "\n",
    "We can limit the impact of the prefix expansion by setting max_expansions to a reasonable number, such as 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'title': 'The quick brown fox'}>, <Hit(my_index/my_type/2): {'title': 'The quick brown fox jumps over the lazy dog'}>, <Hit(my_index/my_type/3): {'title': 'The quick brown fox jumps over the quick dog'}>]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding some control on expansions:\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query(Q('match_phrase_prefix', title={\"query\": \"quick brown f\", \"max_expansions\":2}))\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `max_expansions` parameter controls how many terms the prefix is allowed to match. It will find the first term starting with `f` and keep collecting terms (in alphabetical order) until it either runs out of terms with prefix `f`, or it has more terms than max_expansions.\n",
    "\n",
    "Don’t forget that we have to run this query every time the user types another character, so it needs to be fast. If the first set of results isn’t what users are after, they’ll keep typing until they get the results that they want.\n",
    "\n",
    "#### Ngrams for Partial Matching\n",
    "\n",
    "`Prefix`, `wildcard` and `regexp` queries operate by iterating through the list of indexed terms to match the string pattern. This is expensive versus how search should ideally work, which is to find a token that is already in the index - i.e. let's imagine that the prefix string is already in the index as a separate token.\n",
    "\n",
    "This preparation of the index can be done via tokenizing the docs into n-grams:\n",
    "\n",
    "* Length 1 (unigram): [ q, u, i, c, k ]\n",
    "* Length 2 (bigram): [ qu, ui, ic, ck ]\n",
    "* Length 3 (trigram): [ qui, uic, ick ]\n",
    "* Length 4 (four-gram): [ quic, uick ]\n",
    "* Length 5 (five-gram): [ quick ]\n",
    "\n",
    "For search-as-you-type, _edge n-grams_ are better:\n",
    "\n",
    "* q\n",
    "* qu\n",
    "* qui\n",
    "* quic\n",
    "* quick\n",
    "\n",
    "#### Index-Time Search-as-You-Type\n",
    "\n",
    "Edge n-grams are part of the tokenization process within the analysis flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1, \n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"autocomplete_filter\": { \n",
    "                    \"type\":     \"edge_ngram\",\n",
    "                    \"min_gram\": 1,\n",
    "                    \"max_gram\": 20\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"autocomplete\": {\n",
    "                    \"type\":      \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"autocomplete_filter\" \n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "index.create_my_index(body=body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos 0: (q)\n",
      "Pos 0: (qu)\n",
      "Pos 0: (qui)\n",
      "Pos 0: (quic)\n",
      "Pos 0: (quick)\n",
      "Pos 1: (b)\n",
      "Pos 1: (br)\n",
      "Pos 1: (bro)\n",
      "Pos 1: (brow)\n",
      "Pos 1: (brown)\n"
     ]
    }
   ],
   "source": [
    "# Now let's confirm how this analyzer works:\n",
    "text = \"quick brown\" \n",
    "analyzed_text = [[x['position'],x['token']] for x in es.indices.analyze\\\n",
    "                 (index='my_index', analyzer='autocomplete', text=text)['tokens']]\n",
    "for item in analyzed_text:\n",
    "    print('Pos {}: ({})'.format(item[0],item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the mapping to try it out:\n",
    "mapping = {\n",
    "    \"my_type\": {\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\":     \"string\",\n",
    "                \"analyzer\": \"autocomplete\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es.indices.put_mapping(index='my_index', doc_type='my_type', body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '2',\n",
       " '_index': 'my_index',\n",
       " '_shards': {'failed': 0, 'successful': 1, 'total': 2},\n",
       " '_type': 'my_type',\n",
       " '_version': 1,\n",
       " 'created': True,\n",
       " 'result': 'created'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = { \"name\": \"Brown foxes\"    }\n",
    "es.create(index='my_index', doc_type='my_type', body = doc, id=1)\n",
    "doc = { \"name\": \"Yellow furballs\"    }\n",
    "es.create(index='my_index', doc_type='my_type', body = doc, id=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'name': 'Brown foxes'}>, <Hit(my_index/my_type/2): {'name': 'Yellow furballs'}>]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now try a search:\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query('match', name=\"brown fo\")\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm. What's going on here? Why did Yellow furballs score a hit?\n",
    "\n",
    "Let's validate the query to see what Elasticsearch thinks it's looking for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'Synonym(name:b name:br name:bro name:brow name:brown) Synonym(name:f name:fo)',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = Q('match', name=\"brown fo\").to_dict()\n",
    "es.indices.validate_query(index='my_index', body={\"query\": q}, explain=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query string `name:f` is part of the above query, hence the match with f in furballs.\n",
    "\n",
    "In this case, we want to use the `autocomplete` analyzer at index time, but the `standard` analyzer at search time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'name': 'Brown foxes'}>]>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the standard analyzer at search time\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query('match', name={\"query\":\"brown fo\", \"analyzer\":\"standard\"})\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify this in the mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the mapping to specify different index vs. search analyzers:\n",
    "mapping = {\n",
    "    \"my_type\": {\n",
    "        \"properties\": {\n",
    "            \"name\": {\n",
    "                \"type\":     \"string\",\n",
    "                \"analyzer\": \"autocomplete\",\n",
    "                \"search_analyzer\": \"standard\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "es.indices.put_mapping(index='my_index', doc_type='my_type', body=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response: [<Hit(my_index/my_type/1): {'name': 'Brown foxes'}>]>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now try a search with specifying an analyzer:\n",
    "s = Index('my_index', using=es).search()\n",
    "s = s.query('match', name=\"brown fo\")\n",
    "s.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 1, 'total': 1},\n",
       " 'explanations': [{'explanation': 'name:brown name:fo',\n",
       "   'index': 'my_index',\n",
       "   'valid': True}],\n",
       " 'valid': True}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And let's validate again:\n",
    "q = Q('match', name=\"brown fo\").to_dict()\n",
    "es.indices.validate_query(index='my_index', body={\"query\": q}, explain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
