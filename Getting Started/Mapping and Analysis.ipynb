{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch: The Definitive Guide - Python\n",
    "\n",
    "Following the examples in the book, here are Python snippets that achieve the same effect.\n",
    "\n",
    "Documentation for the Python libs:\n",
    "\n",
    "Low-level API:\n",
    "\n",
    "https://elasticsearch-py.readthedocs.io/en/master/index.html\n",
    "\n",
    "Expressive DSL API (more \"Pythonic\")\n",
    "\n",
    "http://elasticsearch-dsl.readthedocs.io/en/latest/index.html\n",
    "\n",
    "Github repo for DSL API:\n",
    "\n",
    "https://github.com/elastic/elasticsearch-dsl-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search, Q\n",
    "from pprint import pprint\n",
    "\n",
    "es = Elasticsearch(\n",
    "    'localhost',\n",
    "    # sniff before doing anything\n",
    "    sniff_on_start=True,\n",
    "    # refresh nodes after a node fails to respond\n",
    "    sniff_on_connection_fail=True,\n",
    "    # and also every 60 seconds\n",
    "    sniffer_timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping and Analysis\n",
    "\n",
    "> GET /gb/_mapping/tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gb': {'mappings': {'tweet': {'properties': {'date': {'type': 'date'},\n",
      "                                              'name': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                              'type': 'keyword'}},\n",
      "                                                       'type': 'text'},\n",
      "                                              'tweet': {'fields': {'keyword': {'ignore_above': 256,\n",
      "                                                                               'type': 'keyword'}},\n",
      "                                                        'type': 'text'},\n",
      "                                              'user_id': {'type': 'long'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "res = es.indices.get_mapping(index='gb', doc_type='tweet')\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These queries return the same results because the analyzer has tokenized and normalized the string ```2014-09-15``` to ```2014```, ```09```, and ```15```.\n",
    "\n",
    "> GET /_search?q=2014-09-15        # 12 results !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "res = es.search(q='2014-09-15')\n",
    "print(res['hits']['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This search is against the _all meta field and so wherever these values are found (in all tweets), a hit is registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es) \\\n",
    "    .query('match', _all='2014-09-15')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response['hits']['total']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the field explicitly to date, then only the one tweet (with that date) is returned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hits:1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = Search(using=es) \\\n",
    "    .query('match', date='2014-09-15')\n",
    "response = s.execute()\n",
    "print('Total hits:{}\\n'.format(response['hits']['total']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Analyzers\n",
    "\n",
    "We can test analyzers using the _analyze API:\n",
    "```\n",
    "GET /_analyze\n",
    "{\n",
    "  \"analyzer\": \"standard\",\n",
    "  \"text\": \"Text to analyze\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': [{'end_offset': 4,\n",
      "             'position': 0,\n",
      "             'start_offset': 0,\n",
      "             'token': 'text',\n",
      "             'type': '<ALPHANUM>'},\n",
      "            {'end_offset': 7,\n",
      "             'position': 1,\n",
      "             'start_offset': 5,\n",
      "             'token': 'to',\n",
      "             'type': '<ALPHANUM>'},\n",
      "            {'end_offset': 15,\n",
      "             'position': 2,\n",
      "             'start_offset': 8,\n",
      "             'token': 'analyze',\n",
      "             'type': '<ALPHANUM>'}]}\n"
     ]
    }
   ],
   "source": [
    "text = \"Text to analyze\"\n",
    "res = es.indices.analyze(analyzer='standard', body=text)\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the token is the actual term that will be stored in the inverted index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "to\n",
      "analyze\n"
     ]
    }
   ],
   "source": [
    "for token in res['tokens']:\n",
    "    print(token['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Built-in Analyzers (Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"I want to buy an i-pad and use it to purchase some socks on e-bay\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,want,to,buy,an,i,pad,and,use,it,to,purchase,some,socks,on,e,bay\n"
     ]
    }
   ],
   "source": [
    "#standard\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze(analyzer='standard', body=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,want,to,buy,an,i,pad,and,use,it,to,purchase,some,socks,on,e,bay\n"
     ]
    }
   ],
   "source": [
    "#simple\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze(analyzer='simple', body=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I,want,to,buy,an,i-pad,and,use,it,to,purchase,some,socks,on,e-bay\n"
     ]
    }
   ],
   "source": [
    "#whitespace\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze(analyzer='whitespace', body=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,want,bui,i,pad,us,purchas,some,sock,e,bai\n"
     ]
    }
   ],
   "source": [
    "#english (language)\n",
    "analyzed_text = [x['token'] for x in es.indices.analyze(analyzer='english', body=text)['tokens']]\n",
    "print(','.join(analyzed_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Mapping\n",
    "\n",
    "Elasticsearch supports the following simple field types:\n",
    "\n",
    "* String: string\n",
    "* Whole number: byte, short, integer, long\n",
    "* Floating-point: float, double\n",
    "* Boolean: boolean\n",
    "* Date: date\n",
    "\n",
    "> GET /gb/_mapping/tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gb': {'mappings': {'tweet': {'properties': {'date': {'type': 'date'},\n",
       "     'name': {'fields': {'keyword': {'ignore_above': 256, 'type': 'keyword'}},\n",
       "      'type': 'text'},\n",
       "     'tweet': {'fields': {'keyword': {'ignore_above': 256, 'type': 'keyword'}},\n",
       "      'type': 'text'},\n",
       "     'user_id': {'type': 'long'}}}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.get_mapping(index='gb', doc_type='tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these results differ from the book because here we are using Elasticsearch 5.x. The core datatypes [are different](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html)\n",
    "\n",
    "Let's delete the 'gb' index to experiment with different mappings.\n",
    "\n",
    "> DELETE /gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index='gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the index again but with different field mappings. In particular, per the example, we will use a different analyzer (\"english\") for the 'tweet' mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_template = {\n",
    "  \"mappings\": {\n",
    "    \"tweet\" : {\n",
    "      \"properties\" : {\n",
    "        \"tweet\" : {\n",
    "          \"type\" :    \"text\",\n",
    "          \"analyzer\": \"english\"\n",
    "        },\n",
    "        \"date\" : {\n",
    "          \"type\" :   \"date\"\n",
    "        },\n",
    "        \"name\" : {\n",
    "          \"type\" :   \"text\"\n",
    "        },\n",
    "        \"user_id\" : {\n",
    "          \"type\" :   \"long\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index='gb', body=index_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later on, we decide to add a new not_analyzed text field called tag to the tweet mapping, using the _mapping endpoint:\n",
    "\n",
    ">PUT /gb/_mapping/tweet\n",
    "{\n",
    "  \"properties\" : {\n",
    "    \"tag\" : {\n",
    "      \"type\" :    \"string\",\n",
    "      \"index\":    \"not_analyzed\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_template = {\n",
    "  \"properties\" : {\n",
    "    \"tag\" : {\n",
    "      \"type\" :    \"text\",\n",
    "      \"index\":    \"not_analyzed\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "es.indices.put_mapping(index='gb', doc_type='tweet', body=mapping_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the Mapping\n",
    "\n",
    "You can use the analyze API to test the mapping for string fields by name. Compare the output of these two requests:\n",
    "\n",
    ">GET /gb/_analyze\n",
    "{\n",
    "  \"field\": \"tweet\",\n",
    "  \"text\": \"Black-cats\" \n",
    "}\n",
    "\n",
    ">GET /gb/_analyze\n",
    "{\n",
    "  \"field\": \"tag\",\n",
    "  \"text\": \"Black-cats\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tweet = {\n",
    "  \"field\": \"tweet\",\n",
    "  \"text\": \"Black-cats\" \n",
    "}\n",
    "\n",
    "test_tag = {\n",
    "  \"field\": \"tag\",\n",
    "  \"text\": \"Black-cats\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'end_offset': 5,\n",
       "   'position': 0,\n",
       "   'start_offset': 0,\n",
       "   'token': 'black',\n",
       "   'type': '<ALPHANUM>'},\n",
       "  {'end_offset': 10,\n",
       "   'position': 1,\n",
       "   'start_offset': 6,\n",
       "   'token': 'cat',\n",
       "   'type': '<ALPHANUM>'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.analyze(index='gb', body=test_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [{'end_offset': 5,\n",
       "   'position': 0,\n",
       "   'start_offset': 0,\n",
       "   'token': 'black',\n",
       "   'type': '<ALPHANUM>'},\n",
       "  {'end_offset': 10,\n",
       "   'position': 1,\n",
       "   'start_offset': 6,\n",
       "   'token': 'cats',\n",
       "   'type': '<ALPHANUM>'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.analyze(index='gb', body=test_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet field produces the two terms black and cat, while the tag field produces the single term Black-cats. In other words, our mapping is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Core Field Types\n",
    "\n",
    "#### Multivalue Fields\n",
    "\n",
    "It is quite possible that we want our tag field to contain more than one tag. Instead of a single string, we could index an array of tags:\n",
    "\n",
    "> ```{ \"tag\": [ \"search\", \"nosql\" ]}```\n",
    "\n",
    "There is no special mapping required for arrays. Any field can contain zero, one, or more values, in the same way as a full-text field is analyzed to produce multiple terms.\n",
    "\n",
    "Empty fields are also allowed:\n",
    "\n",
    ">\"null_value\":               null,\n",
    "\n",
    ">\"empty_array\":              [],\n",
    "\n",
    ">\"array_with_null_value\":    [ null ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Objects can be nested and accept nest mappings:\n",
    "mapping = {\n",
    "  \"gb\": {\n",
    "    \"tweet\": { \n",
    "      \"properties\": {\n",
    "        \"tweet\":            { \"type\": \"string\" },\n",
    "        \"user\": { \n",
    "          \"type\":             \"object\",\n",
    "          \"properties\": {\n",
    "            \"id\":           { \"type\": \"string\" },\n",
    "            \"gender\":       { \"type\": \"string\" },\n",
    "            \"age\":          { \"type\": \"long\"   },\n",
    "            \"name\":   { \n",
    "              \"type\":         \"object\",\n",
    "              \"properties\": {\n",
    "                \"full\":     { \"type\": \"string\" },\n",
    "                \"first\":    { \"type\": \"string\" },\n",
    "                \"last\":     { \"type\": \"string\" }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Inner Objects are Indexeded\n",
    "\n",
    "Lucene (Elasticsearch's core library) doesnâ€™t understand inner objects. A Lucene document consists of a flat list of key-value pairs. In order for Elasticsearch to index inner objects usefully, it converts our document into something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = {\\n    \"tweet\":            [elasticsearch, flexible, very],\\n    \"user.id\":          [@johnsmith],\\n    \"user.gender\":      [male],\\n    \"user.age\":         [26],\\n    \"user.name.full\":   [john, smith],\\n    \"user.name.first\":  [john],\\n    \"user.name.last\":   [smith]\\n}\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "data = {\n",
    "    \"tweet\":            [elasticsearch, flexible, very],\n",
    "    \"user.id\":          [@johnsmith],\n",
    "    \"user.gender\":      [male],\n",
    "    \"user.age\":         [26],\n",
    "    \"user.name.full\":   [john, smith],\n",
    "    \"user.name.first\":  [john],\n",
    "    \"user.name.last\":   [smith]\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
